#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å±æ€§å¤„ç†æ¨¡å— - AttrPromptå±æ€§åŠ è½½å’Œåˆè§„æ€§è®¡ç®—
"""
import os
import json
import re
import random
from typing import Dict, List, Any

# AttrPromptå±æ€§é…ç½®
ATTRPROMPT_CONFIG = {
    'base_path': '/public/home/huzhenlin2023/paper_2_LLM_Synthesis/synthesis_model_train/TRL-GRPO/yelp/attrprompt/gpt-3.5-turbo',
    'attributes': ['cuisine', 'subtopics', 'style', 'price_range', 'service_quality', 'atmosphere', 'length'],
    'sentiment_labels': ['very negative', 'negative', 'neutral', 'positive', 'very positive']
}

class AttrPromptAttributeLoader:
    """AttrPromptå±æ€§æ•°æ®åŠ è½½å™¨"""
    
    def __init__(self, base_path):
        self.base_path = base_path
        self.attributes_data = {}
        self.load_all_attributes()
    
    def load_attributes(self, attr_name, classes=None):
        """åŠ è½½æŒ‡å®šå±æ€§çš„æ•°æ®"""
        attr_path = os.path.join(self.base_path, attr_name)
        
        # å¯¹äºé€šç”¨å±æ€§ï¼ˆå¦‚cuisine, length, styleï¼‰ï¼ŒåŠ è½½å•ä¸ªæ–‡ä»¶
        general_attrs = ['cuisine', 'length', 'style']
        if attr_name in general_attrs:
            # å°è¯•ä¸åŒçš„æ–‡ä»¶æ ¼å¼
            for ext in ['.txt', '.json']:
                attr_file = os.path.join(attr_path, f"{attr_name}{ext}")
                if os.path.exists(attr_file):
                    try:
                        if ext == '.json':
                            with open(attr_file, 'r', encoding='utf-8') as f:
                                return json.load(f)
                        else:  # .txt format
                            with open(attr_file, 'r', encoding='utf-8') as f:
                                lines = [line.strip() for line in f.readlines() if line.strip()]
                                return lines
                    except Exception as e:
                        print(f"âš ï¸ è¯»å–å±æ€§æ–‡ä»¶å¤±è´¥: {attr_file}, é”™è¯¯: {e}")
                        continue
            print(f"âš ï¸ å±æ€§æ–‡ä»¶ä¸å­˜åœ¨: {attr_path}/{attr_name}.[txt|json]")
            return []
        
        # å¯¹äºæƒ…æ„Ÿç›¸å…³å±æ€§ï¼Œéœ€è¦åŠ è½½å„ä¸ªæƒ…æ„Ÿæ ‡ç­¾çš„æ–‡ä»¶
        else:
            sentiment_data = {}
            for sentiment in ATTRPROMPT_CONFIG['sentiment_labels']:
                # å°è¯•ä¸åŒçš„æ–‡ä»¶æ ¼å¼
                for ext in ['.txt', '.json']:
                    sentiment_file = os.path.join(attr_path, f"{sentiment.replace(' ', '_')}{ext}")
                    if os.path.exists(sentiment_file):
                        try:
                            if ext == '.json':
                                with open(sentiment_file, 'r', encoding='utf-8') as f:
                                    sentiment_data[sentiment] = json.load(f)
                            else:  # .txt format
                                with open(sentiment_file, 'r', encoding='utf-8') as f:
                                    lines = [line.strip() for line in f.readlines() if line.strip()]
                                    sentiment_data[sentiment] = lines
                            break  # æ‰¾åˆ°æ–‡ä»¶å°±é€€å‡ºæ ¼å¼å¾ªç¯
                        except Exception as e:
                            print(f"âš ï¸ è¯»å–æƒ…æ„Ÿå±æ€§æ–‡ä»¶å¤±è´¥: {sentiment_file}, é”™è¯¯: {e}")
                            continue
                else:
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤å€¼
                    sentiment_data[sentiment] = []
            return sentiment_data
    
    def load_all_attributes(self):
        """åŠ è½½æ‰€æœ‰å±æ€§æ•°æ®"""
        print("ğŸ”„ åŠ è½½AttrPromptå±æ€§æ•°æ®...")
        
        for attr in ATTRPROMPT_CONFIG['attributes']:
            try:
                self.attributes_data[attr] = self.load_attributes(attr)
                print(f"   âœ… {attr}: åŠ è½½å®Œæˆ")
            except Exception as e:
                print(f"   âŒ {attr}: åŠ è½½å¤±è´¥ - {e}")
                self.attributes_data[attr] = []
        
        print("âœ… AttrPromptå±æ€§æ•°æ®åŠ è½½å®Œæˆ")
    
    def get_attribute_keywords(self, attr_name, sentiment=None):
        """è·å–å±æ€§çš„å…³é”®è¯åˆ—è¡¨"""
        if attr_name not in self.attributes_data:
            return []
        
        attr_data = self.attributes_data[attr_name]
        
        if isinstance(attr_data, dict) and sentiment:
            return attr_data.get(sentiment, [])
        elif isinstance(attr_data, list):
            return attr_data
        else:
            return []

class AttributeComplianceCalculator:
    """å±æ€§è¦æ±‚ç¬¦åˆåº¦è®¡ç®—å™¨"""
    
    def __init__(self, attr_loader):
        self.attr_loader = attr_loader
    
    def separate_prompt_and_generation(self, completion, prompt=None):
        """æ”¹è¿›çš„promptå’Œgenerationåˆ†ç¦»é€»è¾‘ - ä¸“æ³¨äºJSONç»“æ„æå–"""
        try:
            # æ–¹æ³•1: å°è¯•ä»input/output JSONç»“æ„ä¸­æå–å†…å®¹
            json_obj = self._find_input_output_json(completion)
            if json_obj and 'input' in json_obj:
                input_text = json_obj['input']
                if isinstance(input_text, str):
                    # ç§»é™¤"Text: "å‰ç¼€ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                    if input_text.startswith("Text: "):
                        return input_text[6:].strip()
                    return input_text.strip()
            
            # æ–¹æ³•2: å°è¯•å¯»æ‰¾"Text: "æ¨¡å¼
            text_patterns = [
                r'"input"\s*:\s*"Text:\s*([^"]+)"',
                r'"input"\s*:\s*"([^"]+)"',
                r'Text:\s*([^\n}]+)',
            ]
            
            import re
            for pattern in text_patterns:
                match = re.search(pattern, completion, re.DOTALL | re.IGNORECASE)
                if match:
                    extracted = match.group(1).strip()
                    if len(extracted) > 20:  # ç¡®ä¿æå–çš„å†…å®¹æœ‰æ„ä¹‰
                        return extracted
            
            # æ–¹æ³•3: å°è¯•æå–JSONåçš„ç¬¬ä¸€æ®µæœ‰æ„ä¹‰çš„æ–‡æœ¬
            json_start = completion.find('{')
            if json_start != -1:
                # æ‰¾åˆ°JSONç»“æŸä½ç½®
                brace_count = 0
                json_end = -1
                for i in range(json_start, len(completion)):
                    if completion[i] == '{':
                        brace_count += 1
                    elif completion[i] == '}':
                        brace_count -= 1
                        if brace_count == 0:
                            json_end = i + 1
                            break
                
                if json_end != -1:
                    # æå–JSONåçš„å†…å®¹ä½œä¸ºfallback
                    remaining = completion[json_end:].strip()
                    if remaining and len(remaining) > 20:
                        # æ¸…ç†å¹¶è¿”å›ç¬¬ä¸€æ®µæœ‰æ„ä¹‰çš„æ–‡æœ¬
                        lines = remaining.split('\n')
                        for line in lines:
                            line = line.strip()
                            if len(line) > 20 and not line.startswith('#'):
                                return line
            
            # æ–¹æ³•4: ç®€å•çš„æ–‡æœ¬æ¸…ç†ä½œä¸ºæœ€åæ‰‹æ®µ
            if len(completion) > 50:
                # ç§»é™¤æ˜æ˜¾çš„ä»£ç æ ‡è®°
                cleaned = completion
                patterns_to_remove = [
                    r'```[^`]*```',  # ä»£ç å—
                    r'def\s+\w+\([^)]*\):',  # å‡½æ•°å®šä¹‰
                    r'import\s+\w+',  # importè¯­å¥
                    r'#.*$',  # æ³¨é‡Š
                ]
                
                for pattern in patterns_to_remove:
                    cleaned = re.sub(pattern, '', cleaned, flags=re.MULTILINE)
                
                # å–å‰200ä¸ªå­—ç¬¦ä½œä¸ºç”Ÿæˆå†…å®¹
                cleaned = cleaned.strip()
                if len(cleaned) > 20:
                    return cleaned[:200] + "..." if len(cleaned) > 200 else cleaned
            
            # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œè¿”å›æˆªæ–­çš„åŸå§‹å†…å®¹
            return completion[:100] + "..." if len(completion) > 100 else completion
            
        except Exception as e:
            print(f"âš ï¸ æ–‡æœ¬åˆ†ç¦»å¤±è´¥: {e}")
            return completion[:100] + "..." if len(completion) > 100 else completion

    def extract_text_from_completion(self, completion, prompt=None):
        """ä»completionä¸­æå–å®é™…çš„è¯„è®ºæ–‡æœ¬"""
        try:
            # å¯¼å…¥å…¨å±€å‡½æ•°
            from .novelsum_diversity import separate_prompt_and_generation_global
            
            # é¦–å…ˆåˆ†ç¦»å‡ºçœŸæ­£çš„ç”Ÿæˆå†…å®¹
            if prompt is not None:
                generation = self.separate_prompt_and_generation(completion, prompt)
            else:
                generation = separate_prompt_and_generation_global(completion)
            
            # å°è¯•ä»JSONä¸­æå–
            if "{" in generation and "}" in generation:
                start_idx = generation.find("{")
                end_idx = generation.rfind("}") + 1
                json_str = generation[start_idx:end_idx]
                parsed_data = json.loads(json_str)
                input_text = parsed_data.get("input", "")
                if input_text.startswith("Text: "):
                    return input_text[6:]
                return input_text
        except:
            pass
        
        # å¦‚æœJSONè§£æå¤±è´¥ï¼Œè¿”å›å¤„ç†åçš„æ–‡æœ¬
        return (generation if 'generation' in locals() else completion)

    def extract_sentiment_from_json(self, completion):
        """ä»JSONæ ¼å¼çš„completionä¸­æå–æƒ…æ„Ÿæ ‡ç­¾ - åŸºäºinput/outputå­—æ®µçš„æ™ºèƒ½æå–"""
        try:
            # æ–¹æ³•1: å¯»æ‰¾åŒ…å«"input"å’Œ"output"å­—æ®µçš„JSONç»“æ„
            json_obj = self._find_input_output_json(completion)
            if json_obj:
                return self._extract_sentiment_from_parsed_json(json_obj)
            
            # æ–¹æ³•2: å¦‚æœæ–¹æ³•1å¤±è´¥ï¼Œå°è¯•ä¼ ç»Ÿçš„JSONæå–
            json_obj = self._find_first_complete_json(completion)
            if json_obj:
                return self._extract_sentiment_from_parsed_json(json_obj)
            
            # æ–¹æ³•3: å¤‡ç”¨æå–
            return self._fallback_sentiment_extraction(completion)
                
        except Exception as e:
            print(f"âš ï¸ JSONè§£æå¤±è´¥: {str(e)[:50]}")
            return self._fallback_sentiment_extraction(completion)
    
    def _find_input_output_json(self, text):
        """å¯»æ‰¾åŒ…å«inputå’Œoutputå­—æ®µçš„JSONå¯¹è±¡"""
        import re
        import json
        
        # å¯»æ‰¾"input"å…³é”®å­—çš„ä½ç½®
        input_matches = list(re.finditer(r'"input"\s*:', text, re.IGNORECASE))
        
        for input_match in input_matches:
            input_pos = input_match.start()
            
            # å‘å‰å¯»æ‰¾æœ€è¿‘çš„å¼€æ‹¬å·{
            json_start = -1
            for i in range(input_pos - 1, -1, -1):
                if text[i] == '{':
                    json_start = i
                    break
                elif text[i] == '}':  # å¦‚æœé‡åˆ°}ï¼Œè¯´æ˜è¿™ä¸ªinputä¸å±äºæˆ‘ä»¬è¦æ‰¾çš„JSON
                    break
            
            if json_start == -1:
                continue
            
            # ä»json_startå¼€å§‹å¯»æ‰¾å®Œæ•´çš„JSON
            json_obj = self._extract_json_from_position(text, json_start)
            if json_obj and 'input' in json_obj and 'output' in json_obj:
                return json_obj
        
        return None
    
    def _find_first_complete_json(self, text):
        """å¯»æ‰¾ç¬¬ä¸€ä¸ªå®Œæ•´çš„JSONå¯¹è±¡"""
        import json
        
        json_start = text.find('{')
        if json_start == -1:
            return None
        
        return self._extract_json_from_position(text, json_start)
    
    def _extract_json_from_position(self, text, start_pos):
        """ä»æŒ‡å®šä½ç½®å¼€å§‹æå–å®Œæ•´çš„JSONå¯¹è±¡"""
        import json
        
        try:
            # å¯»æ‰¾åŒ¹é…çš„ç»“æŸå¤§æ‹¬å·
            brace_count = 0
            json_end = -1
            
            for i in range(start_pos, len(text)):
                char = text[i]
                if char == '{':
                    brace_count += 1
                elif char == '}':
                    brace_count -= 1
                    if brace_count == 0:
                        json_end = i + 1
                        break
            
            if json_end == -1:
                return None
            
            # æå–å¹¶æ¸…ç†JSONå­—ç¬¦ä¸²
            json_str = text[start_pos:json_end]
            json_str = self._clean_json_string_simple(json_str)
            
            # å°è¯•è§£æ
            return json.loads(json_str)
            
        except:
            return None
    
    def _clean_json_string_simple(self, json_str):
        """ç®€å•çš„JSONå­—ç¬¦ä¸²æ¸…ç†"""
        # ç§»é™¤æ§åˆ¶å­—ç¬¦ä½†ä¿ç•™åŸºæœ¬æ ¼å¼
        import re
        
        # ç§»é™¤å±é™©çš„æ§åˆ¶å­—ç¬¦
        json_str = re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]', '', json_str)
        
        # è§„èŒƒåŒ–ç©ºç™½å­—ç¬¦
        json_str = re.sub(r'\s+', ' ', json_str)
        
        return json_str.strip()
    
    def _extract_sentiment_from_parsed_json(self, json_obj):
        """ä»å·²è§£æçš„JSONå¯¹è±¡ä¸­æå–æƒ…æ„Ÿæ ‡ç­¾"""
        if not isinstance(json_obj, dict):
            return ""
        
        # ä¼˜å…ˆæŸ¥æ‰¾outputå­—æ®µ
        output_keys = ['output', 'sentiment', 'response', 'result', 'answer']
        for key in output_keys:
            if key in json_obj:
                output = json_obj[key]
                if isinstance(output, list):
                    output = output[0] if output else ""
                elif output is not None:
                    output = str(output).strip()
                
                # éªŒè¯æ˜¯å¦æ˜¯æœ‰æ•ˆçš„æƒ…æ„Ÿæ ‡ç­¾
                if self._is_valid_sentiment(output):
                    return output
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡å‡†é”®ï¼Œæœç´¢åŒ…å«æƒ…æ„Ÿè¯çš„å€¼
        for key, value in json_obj.items():
            if isinstance(value, str):
                value = value.strip()
                if self._is_valid_sentiment(value):
                    return value
        
        return ""
    
    def _is_valid_sentiment(self, text):
        """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦æ˜¯æœ‰æ•ˆçš„æƒ…æ„Ÿæ ‡ç­¾"""
        if not text:
            return False
        
        text_lower = text.lower().strip()
        valid_sentiments = [
            'very negative', 'very positive', 'negative', 'positive', 'neutral'
        ]
        
        return text_lower in valid_sentiments
    
    def _fallback_sentiment_extraction(self, completion):
        """å¤‡ç”¨æƒ…æ„Ÿæå–æ–¹æ³•ï¼Œä½¿ç”¨ç®€å•çš„å­—ç¬¦ä¸²åŒ¹é…"""
        # ç›´æ¥æœç´¢æƒ…æ„Ÿè¯ï¼Œä¸ä½¿ç”¨å¤æ‚çš„æ­£åˆ™è¡¨è¾¾å¼
        sentiments = ['very negative', 'very positive', 'negative', 'positive', 'neutral']
        
        completion_lower = completion.lower()
        for sentiment in sentiments:
            if sentiment in completion_lower:
                return sentiment
        
        return ""

    def calculate_sentiment_consistency(self, completion, target_sentiment):
        """è®¡ç®—æƒ…æ„Ÿæ ‡ç­¾ä¸€è‡´æ€§"""
        extracted_sentiment = self.extract_sentiment_from_json(completion)
        
        # ä¿®å¤ï¼šç¡®ä¿extracted_sentimentæ˜¯å­—ç¬¦ä¸²
        if isinstance(extracted_sentiment, list):
            extracted_sentiment = extracted_sentiment[0] if extracted_sentiment else ""
        elif not isinstance(extracted_sentiment, str):
            extracted_sentiment = str(extracted_sentiment) if extracted_sentiment else ""
        
        if not extracted_sentiment:
            return 0.0
        
        # ç²¾ç¡®åŒ¹é…
        if extracted_sentiment.lower() == target_sentiment.lower():
            return 1.0
        
        # éƒ¨åˆ†åŒ¹é…ï¼ˆä¾‹å¦‚ï¼špositive vs very positiveï¼‰
        similarity_mapping = {
            'very negative': ['negative', 'very_negative'],
            'negative': ['very negative', 'very_negative'],
            'neutral': ['mixed', 'average', 'okay'],
            'positive': ['very positive', 'very_positive', 'good'],
            'very positive': ['positive', 'very_positive', 'excellent']
        }
        
        target_lower = target_sentiment.lower()
        extracted_lower = extracted_sentiment.lower()
        
        if target_lower in similarity_mapping:
            if any(similar in extracted_lower for similar in similarity_mapping[target_lower]):
                return 0.7
        
        return 0.0  # å®Œå…¨ä¸åŒ¹é…
    
    def calculate_cuisine_compliance(self, completion, target_cuisine):
        """è®¡ç®—èœç³»åŒ¹é…åº¦"""
        if not target_cuisine or target_cuisine.lower() == 'default_value':
            return 0.5
        
        completion_lower = completion.lower()
        target_lower = target_cuisine.lower()
        
        # ç›´æ¥åŒ¹é…èœç³»åç§°
        if target_lower in completion_lower:
            return 1.0
        
        # èœç³»ç›¸å…³å…³é”®è¯åŒ¹é…
        cuisine_keywords = {
            # å·²æœ‰çš„èœç³»
            'mexican': ['taco', 'burrito', 'salsa', 'guacamole', 'quesadilla', 'enchilada', 'fajita'],
            'chinese': ['dim sum', 'noodles', 'rice', 'stir fry', 'dumpling', 'wontons', 'fried rice'],
            'italian': ['pasta', 'pizza', 'marinara', 'parmesan', 'risotto', 'lasagna', 'ravioli'],
            'indian': ['curry', 'naan', 'biryani', 'tandoor', 'masala', 'dal', 'samosa'],
            'thai': ['pad thai', 'tom yum', 'coconut', 'lemongrass', 'basil', 'curry', 'satay'],
            'japanese': ['sushi', 'sashimi', 'ramen', 'tempura', 'miso', 'udon', 'teriyaki'],
            'american': ['burger', 'fries', 'bbq', 'sandwich', 'steak', 'ribs', 'wings'],
            'french': ['croissant', 'baguette', 'wine', 'cheese', 'bistro', 'ratatouille', 'crÃªpe'],
            'portuguese': ['bacalhau', 'cod', 'pastÃ©is', 'francesinha', 'caldo verde', 'sardines', 'port wine', 'custard tart'],
            'brazilian': ['churrasco', 'picanha', 'feijoada', 'pÃ£o de aÃ§Ãºcar', 'caipirinha', 'aÃ§aÃ­'],
            'spanish': ['paella', 'tapas', 'gazpacho', 'sangria', 'chorizo', 'jamÃ³n'],
            'korean': ['kimchi', 'bulgogi', 'bibimbap', 'korean bbq', 'galbi', 'banchan'],
            'vietnamese': ['pho', 'banh mi', 'spring rolls', 'vermicelli', 'fish sauce'],
            'greek': ['gyros', 'tzatziki', 'moussaka', 'feta', 'olive oil', 'souvlaki'],
            
            # æ–°å¢èœç³»
            'turkish': ['kebab', 'dÃ¶ner', 'baklava', 'turkish delight', 'bÃ¶rek', 'lahmacun'],
            'cajun': ['jambalaya', 'gumbo', 'crawfish', 'beignet', 'andouille', 'etouffee'],
            'tex-mex': ['nachos', 'fajitas', 'chili con carne', 'queso', 'jalapeÃ±o', 'chimichangas'],
            'peruvian': ['ceviche', 'quinoa', 'anticuchos', 'pisco', 'aji amarillo', 'causa'],
            'argentinean': ['empanadas', 'asado', 'chimichurri', 'malbec', 'dulce de leche'],
            'colombian': ['arepa', 'bandeja paisa', 'sancocho', 'aguardiente', 'patacon'],
            'venezuelan': ['cachapa', 'hallaca', 'tequeÃ±os', 'pabellÃ³n', 'chicha'],
            'ethiopian': ['injera', 'berbere', 'doro wat', 'kitfo', 'tej', 'coffee ceremony'],
            'moroccan': ['tagine', 'couscous', 'harissa', 'pastilla', 'mint tea', 'preserved lemon'],
            'south african': ['biltong', 'boerewors', 'bobotie', 'sosaties', 'potjiekos'],
            'nigerian': ['jollof rice', 'suya', 'egusi', 'plantain', 'pepper soup', 'fufu'],
            'egyptian': ['ful medames', 'koshari', 'molokheya', 'falafel', 'tahini'],
            'malaysian': ['laksa', 'rendang', 'char kway teow', 'satay', 'roti canai'],
            'singaporean': ['hainanese chicken rice', 'laksa', 'char siu', 'chili crab'],
            'indonesian': ['nasi goreng', 'satay', 'rendang', 'gado-gado', 'sambal'],
            'lebanese': ['hummus', 'tabbouleh', 'fattoush', 'kibbeh', 'shawarma', 'baklava'],
            'mediterranean': ['olive oil', 'hummus', 'pita', 'feta', 'olives', 'grilled fish'],
            'middle eastern': ['hummus', 'falafel', 'shawarma', 'pita', 'tahini', 'za\'atar'],
            'russian': ['borscht', 'pierogi', 'caviar', 'vodka', 'beef stroganoff', 'blini'],
            'german': ['schnitzel', 'sauerkraut', 'bratwurst', 'pretzel', 'beer', 'strudel'],
            'polish': ['pierogi', 'kielbasa', 'golumpki', 'bigos', 'kapusta'],
            'scandinavian': ['lutefisk', 'gravlax', 'aquavit', 'meatballs', 'lingonberry'],
            'austrian': ['schnitzel', 'sachertorte', 'apfelstrudel', 'goulash'],
            'swiss': ['fondue', 'raclette', 'rÃ¶sti', 'cheese', 'chocolate'],
            'canadian': ['poutine', 'maple syrup', 'tourtiÃ¨re', 'butter tart', 'nanaimo bar'],
            'australian': ['meat pie', 'vegemite', 'lamington', 'pavlova', 'barbie'],
            'new zealand': ['pavlova', 'hangi', 'green-lipped mussel', 'hokey pokey'],
            'polynesian': ['poi', 'kalua pig', 'lomi lomi', 'taro', 'coconut'],
            'hawaiian': ['poke', 'luau', 'kalua pig', 'lomi lomi salmon', 'shave ice', 'spam musubi']
        }
        
        if target_lower in cuisine_keywords:
            keywords = cuisine_keywords[target_lower]
            matches = sum(1 for keyword in keywords if keyword in completion_lower)
            return min(matches * 0.3, 1.0)
        
        return 0.0
    
    def calculate_length_compliance(self, completion, target_length, tolerance=25):
        """è®¡ç®—é•¿åº¦ç¬¦åˆåº¦ - æ”¯æŒèŒƒå›´å’Œå•ä¸€ç›®æ ‡å€¼"""
        try:
            # ä»completionä¸­æå–å®é™…æ–‡æœ¬
            text_content = self.extract_text_from_completion(completion)
            actual_length = len(text_content.split())
            
            # è°ƒè¯•ä¿¡æ¯
            print(f"DEBUG: target_lengthç±»å‹: {type(target_length)}, å€¼: {target_length}")
            print(f"DEBUG: actual_length: {actual_length}")
            
            # å¤„ç†ä¸åŒæ ¼å¼çš„target_length
            if isinstance(target_length, dict):
                # æ–°æ ¼å¼ï¼šåŒ…å«èŒƒå›´ä¿¡æ¯
                min_length = target_length['min']
                max_length = target_length['max']
                target_value = target_length['target']
                
                # å¦‚æœåœ¨åŸå§‹è¦æ±‚èŒƒå›´å†…ï¼Œç»™æ»¡åˆ†
                if min_length <= actual_length <= max_length:
                    return 1.0
                
                # å¦‚æœåœ¨æ‰©å±•å®¹å¿èŒƒå›´å†…ï¼Œæ ¹æ®è·ç¦»ç»™åˆ†
                extended_min = min_length - tolerance
                extended_max = max_length + tolerance
                
                if extended_min <= actual_length <= extended_max:
                    if actual_length < min_length:
                        # çŸ­äºè¦æ±‚èŒƒå›´
                        diff = min_length - actual_length
                        score = 1.0 - (diff / tolerance) * 0.5
                    else:
                        # é•¿äºè¦æ±‚èŒƒå›´
                        diff = actual_length - max_length
                        score = 1.0 - (diff / tolerance) * 0.5
                    return max(score, 0.5)
                else:
                    return 0.0
                    
            else:
                # æ—§æ ¼å¼ï¼šå•ä¸€ç›®æ ‡å€¼ - è¿™é‡Œå¯èƒ½æ˜¯é—®é¢˜æ‰€åœ¨
                print(f"DEBUG: ä½¿ç”¨æ—§æ ¼å¼ï¼Œtarget_length: {target_length}")
                target_value = int(target_length) if isinstance(target_length, str) else target_length
                length_diff = abs(actual_length - target_value)
                
                if length_diff <= tolerance:
                    # åœ¨å®¹å¿èŒƒå›´å†…ï¼Œæ ¹æ®å·®å¼‚ç»™åˆ†
                    score = 1.0 - (length_diff / tolerance) * 0.3
                    return max(score, 0.7)
                elif length_diff <= tolerance * 2:
                    # è¶…å‡ºå®¹å¿èŒƒå›´ä½†ä¸å¤ªå¤š
                    return 0.5
                else:
                    return 0.0  # è¶…å‡ºèŒƒå›´å¤ªå¤š
        except Exception as e:
            print(f"DEBUG: calculate_length_complianceå¼‚å¸¸: {e}")
            return 0.0
    
    def calculate_attribute_keyword_match(self, completion, attr_name, target_value, sentiment=None):
        """è®¡ç®—å±æ€§å…³é”®è¯åŒ¹é…åº¦"""
        if not target_value or target_value.lower() == 'default_value':
            return 0.5
        
        completion_lower = completion.lower()
        target_lower = target_value.lower()
        
        # ç›´æ¥åŒ¹é…
        if target_lower in completion_lower:
            return 1.0
        
        # ç‰¹å®šå±æ€§çš„å…³é”®è¯åŒ¹é…
        score = self._calculate_specific_attribute_match(completion_lower, attr_name, target_lower)
        if score > 0:
            return score
        
        # è·å–å±æ€§ç›¸å…³å…³é”®è¯ï¼ˆä»æ•°æ®æ–‡ä»¶ï¼‰
        keywords = self.attr_loader.get_attribute_keywords(attr_name, sentiment)
        
        if not keywords:
            return 0.0
        
        # å…³é”®è¯åŒ¹é…åº¦è®¡ç®—
        matches = 0
        for keyword in keywords:
            if isinstance(keyword, str) and keyword.lower() in completion_lower:
                matches += 1
        
        return min(matches * 0.2, 1.0)
    
    def _calculate_specific_attribute_match(self, completion_lower, attr_name, target_lower):
        """é’ˆå¯¹ç‰¹å®šå±æ€§çš„å…³é”®è¯åŒ¹é…"""
        
        # Styleå±æ€§åŒ¹é…
        if attr_name == 'style':
            style_keywords = {
                'descriptive': ['detailed', 'vivid', 'description', 'describes', 'picture'],
                'personal narrative': ['i went', 'my experience', 'we visited', 'personal', 'story'],
                'analysis': ['quality', 'evaluate', 'assess', 'rating', 'pros and cons'],
                'comparative': ['compared to', 'similar to', 'better than', 'versus', 'like other'],
                'gastronomic': ['flavor', 'taste', 'seasoning', 'cooking', 'preparation'],
                'casual conversational': ['honestly', 'so', 'really', 'pretty good', 'not bad'],
                'critical professional': ['professional', 'critique', 'evaluation', 'standards'],
                'enthusiastic emotional': ['amazing', 'fantastic', 'terrible', 'incredible', 'love'],
                'storytelling': ['arrived', 'started', 'then', 'finally', 'journey', 'experience'],
                'humorous': ['funny', 'joke', 'hilarious', 'amusing', 'witty']
            }
            
            for style_type, keywords in style_keywords.items():
                if style_type in target_lower:
                    matches = sum(1 for kw in keywords if kw in completion_lower)
                    if matches > 0:
                        return min(matches * 0.3, 1.0)
        
        # Price rangeå±æ€§åŒ¹é…
        elif attr_name == 'price_range':
            price_keywords = {
                'budget-friendly': ['cheap', 'affordable', 'budget', 'inexpensive', '$'],
                'very affordable': ['very cheap', 'super affordable', 'bargain', 'dirt cheap'],
                'reasonably priced': ['reasonable', 'fair price', 'decent price', 'good value'],
                'moderate': ['moderate', 'average price', 'mid-range', 'not too expensive'],
                'slightly expensive': ['bit pricey', 'somewhat expensive', 'higher end'],
                'upscale': ['upscale', 'premium', 'high-end', 'fancy', '$$$'],
                'fine dining': ['fine dining', 'luxury', 'expensive', '$$$$'],
                'premium': ['premium', 'top tier', 'high-end', 'luxury'],
                'luxury': ['luxury', 'extravagant', 'splurge', 'high-end']
            }
            
            for price_type, keywords in price_keywords.items():
                if price_type in target_lower:
                    matches = sum(1 for kw in keywords if kw in completion_lower)
                    if matches > 0:
                        return min(matches * 0.4, 1.0)
        
        # Service qualityå±æ€§åŒ¹é…
        elif attr_name == 'service_quality':
            service_keywords = {
                'excellent': ['excellent', 'outstanding', 'exceptional', 'perfect', 'amazing'],
                'good': ['good', 'great', 'friendly', 'attentive', 'helpful'],
                'hit-or-miss': ['inconsistent', 'mixed', 'sometimes good', 'hit or miss'],
                'poor': ['poor', 'bad', 'terrible', 'rude', 'slow', 'inattentive'],
                'fast': ['quick', 'fast', 'prompt', 'speedy'],
                'slow': ['slow', 'took forever', 'waited long', 'delayed']
            }
            
            for service_type, keywords in service_keywords.items():
                if service_type in target_lower:
                    matches = sum(1 for kw in keywords if kw in completion_lower)
                    if matches > 0:
                        return min(matches * 0.4, 1.0)
        
        # Atmosphereå±æ€§åŒ¹é…
        elif attr_name == 'atmosphere':
            atmosphere_keywords = {
                'cozy': ['cozy', 'warm', 'intimate', 'comfortable'],
                'elegant': ['elegant', 'sophisticated', 'classy', 'upscale'],
                'casual': ['casual', 'relaxed', 'laid-back', 'informal'],
                'romantic': ['romantic', 'intimate', 'candlelit', 'date night'],
                'family-friendly': ['family', 'kids', 'children', 'families'],
                'lively': ['lively', 'energetic', 'bustling', 'vibrant'],
                'quiet': ['quiet', 'peaceful', 'calm', 'serene'],
                'nothing special': ['nothing special', 'ordinary', 'basic', 'unremarkable', 'plain']
            }
            
            for atm_type, keywords in atmosphere_keywords.items():
                if atm_type in target_lower:
                    matches = sum(1 for kw in keywords if kw in completion_lower)
                    if matches > 0:
                        return min(matches * 0.4, 1.0)
        
        return 0.0

def extract_attributes_from_input(input_text):
    """ä»æµ‹è¯•æ•°æ®çš„inputå­—æ®µä¸­æå–æ‰€æœ‰å±æ€§ä¿¡æ¯"""
    attributes = {}
    
    # æå–ç›®æ ‡æƒ…æ„Ÿæ ‡ç­¾ - ä¿®å¤æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å®é™…æ ¼å¼
    target_patterns = [
        r"The overall review should be ([a-zA-Z\s]+)",
        r"Generate exactly one review with ([a-zA-Z\s]+) sentiment",
        r"sentiment label exactly as provided[^:]*:\s*([a-zA-Z\s]+)",
        r"Target sentiment for generation:\s*([a-zA-Z\s]+)"
    ]
    
    for pattern in target_patterns:
        target_match = re.search(pattern, input_text, re.IGNORECASE)
        if target_match:
            sentiment = target_match.group(1).strip()
            # æ ‡å‡†åŒ–æƒ…æ„Ÿæ ‡ç­¾
            sentiment_mapping = {
                'very negative': 'very negative',
                'negative': 'negative', 
                'neutral': 'neutral',
                'positive': 'positive',
                'very positive': 'very positive'
            }
            attributes['target_sentiment'] = sentiment_mapping.get(sentiment.lower(), sentiment)
            break
    
    # å¦‚æœè¿˜æ²¡æ‰¾åˆ°ï¼Œå°è¯•æ›´å®½æ³›çš„æœç´¢
    if 'target_sentiment' not in attributes:
        # æœç´¢åŒ…å«æƒ…æ„Ÿè¯çš„å¥å­
        sentiment_words = ['very negative', 'negative', 'neutral', 'positive', 'very positive']
        for word in sentiment_words:
            if word in input_text.lower():
                attributes['target_sentiment'] = word
                break
    
    # Amazonæ•°æ®é›†ä¸éœ€è¦æå–é¤å…ç±»å‹å’Œå­ä¸»é¢˜
    # è¿™äº›æ˜¯Yelpæ•°æ®é›†ç‰¹æœ‰çš„å±æ€§
    
    # æå–é•¿åº¦è¦æ±‚
    length_pattern = r"Should be in length between (\d+) words and (\d+) words"
    length_match = re.search(length_pattern, input_text)
    if length_match:
        min_length, max_length = int(length_match.group(1)), int(length_match.group(2))
        # å­˜å‚¨å®Œæ•´çš„é•¿åº¦èŒƒå›´ä¿¡æ¯
        attributes['length'] = {
            'min': min_length,
            'max': max_length,
            'target': (min_length + max_length) // 2
        }
    
    # æå–å†™ä½œé£æ ¼
    style_pattern = r"The style of the review should be '([^']+)'"
    style_match = re.search(style_pattern, input_text)
    if style_match:
        attributes['style'] = style_match.group(1).strip()
    
    # æå–ä»·æ ¼æ–¹é¢
    price_pattern = r"The pricing aspect should reflect '([^']+)'"
    price_match = re.search(price_pattern, input_text)
    if price_match:
        attributes['price_range'] = price_match.group(1).strip()
    
    # æå–æœåŠ¡è´¨é‡
    service_pattern = r"The service quality should be described as '([^']+)'"
    service_match = re.search(service_pattern, input_text)
    if service_match:
        attributes['service_quality'] = service_match.group(1).strip()
    
    # æå–æ°›å›´æè¿°
    atmosphere_pattern = r"The atmosphere should be portrayed as '([^']+)'"
    atmosphere_match = re.search(atmosphere_pattern, input_text)
    if atmosphere_match:
        attributes['atmosphere'] = atmosphere_match.group(1).strip()
    
    return attributes

def generate_random_prompt_attributes(attr_loader):
    """ç”Ÿæˆéšæœºçš„æç¤ºå±æ€§ç»„åˆï¼ˆå…¼å®¹æ€§å‡½æ•°ï¼Œä»…åœ¨æ— æ³•ä»inputæå–æ—¶ä½¿ç”¨ï¼‰"""
    if not attr_loader:
        return {}
    
    # éšæœºé€‰æ‹©ä¸€ä¸ªæƒ…æ„Ÿæ ‡ç­¾
    target_sentiment = random.choice(ATTRPROMPT_CONFIG['sentiment_labels'])
    
    # ç”Ÿæˆå±æ€§ç»„åˆ
    attributes = {}
    
    for attr_name in ATTRPROMPT_CONFIG['attributes']:
        if attr_name == 'length':
            attributes[attr_name] = random.choice([100, 150, 200, 250, 300])
        else:
            keywords = attr_loader.get_attribute_keywords(attr_name, target_sentiment)
            if keywords:
                if isinstance(keywords, list) and keywords:
                    attributes[attr_name] = random.choice(keywords)
                elif isinstance(keywords, dict):
                    # å¯¹äºåµŒå¥—å­—å…¸ï¼Œéšæœºé€‰æ‹©ä¸€ä¸ªå€¼
                    all_values = []
                    for v in keywords.values():
                        if isinstance(v, list):
                            all_values.extend(v)
                    if all_values:
                        attributes[attr_name] = random.choice(all_values)
                else:
                    attributes[attr_name] = 'default_value'
            else:
                attributes[attr_name] = 'default_value'
    
    attributes['target_sentiment'] = target_sentiment
    return attributes