import json
import os
from datasets import Dataset

def load_synthesis_data(file_path, max_samples=None):
    """åŠ è½½åˆæˆæ•°æ®"""
    print(f"Loading synthesis data from {file_path}")
    
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    if max_samples:
        data = data[:max_samples]
    
    # æ ¼å¼åŒ–æ•°æ®
    formatted_data = []
    for item in data:
        if isinstance(item, dict) and 'instruction' in item and 'input' in item and 'output' in item:
            formatted_item = {
                'instruction': item['instruction'],
                'input': item['input'],
                'output': item['output']
            }
            formatted_data.append(formatted_item)
        else:
            print(f"âš ï¸ è·³è¿‡ä¸æ”¯æŒçš„æ•°æ®æ ¼å¼: {list(item.keys())}")
    
    print(f"Loaded {len(formatted_data)} samples")
    return formatted_data

def create_label_grouped_dataset(data, batch_size=4):
    """åˆ›å»ºæŒ‰MNLIæ ‡ç­¾åˆ†ç»„çš„æ•°æ®é›†ï¼Œä¼˜åŒ–å°batchè®­ç»ƒ"""
    print(f"ğŸ”„ æŒ‰MNLIæ ‡ç­¾é‡ç»„æ•°æ®é›† (ç›®æ ‡batchå¤§å°: {batch_size})...")
    
    # æŒ‰MNLIæ ‡ç­¾åˆ†ç»„
    mnli_labels = ["entailment", "contradiction", "neutral"]
    
    label_groups = {label: [] for label in mnli_labels}
    
    for item in data:
        label = item.get('label', 'neutral')
        if label in label_groups:
            label_groups[label].append(item)
        else:
            # å¤„ç†æœªçŸ¥æ ‡ç­¾
            print(f"âš ï¸ æœªçŸ¥æ ‡ç­¾: {label}ï¼Œå½’ç±»ä¸ºneutral")
            label_groups['neutral'].append(item)
                
    
    # æ‰“å°åˆ†ç»„ç»Ÿè®¡
    print("ğŸ“Š MNLIæ ‡ç­¾åˆ†ç»„ç»Ÿè®¡:")
    for label, items in label_groups.items():
        if items:  # åªæ˜¾ç¤ºæœ‰æ ·æœ¬çš„æ ‡ç­¾
            print(f"   {label}: {len(items)}ä¸ªæ ·æœ¬")
    
    # é‡æ–°ç»„ç»‡æ•°æ®ï¼Œç¡®ä¿åŒä¸€batchå†…å°½å¯èƒ½æ˜¯åŒä¸€æ ‡ç­¾
    reorganized_data = []
    
    # ä¸ºæ¯ä¸ªæ ‡ç­¾åˆ›å»ºå®Œæ•´çš„batch
    for label, items in label_groups.items():
        if items:  # åªå¤„ç†éç©ºçš„ç»„
            # å°†è¯¥æ ‡ç­¾çš„æ ·æœ¬æŒ‰batch_sizeåˆ†ç»„
            for i in range(0, len(items), batch_size):
                batch_items = items[i:i + batch_size]
                reorganized_data.extend(batch_items)
                print(f"   æ·»åŠ {label}æ‰¹æ¬¡: {len(batch_items)}ä¸ªæ ·æœ¬")
    
    print(f"âœ… æ•°æ®é‡ç»„å®Œæˆ: {len(reorganized_data)}ä¸ªæ ·æœ¬")
    print(f"ğŸ¯ é¢„æœŸbatchæ•°: {len(reorganized_data) // batch_size}")
    
    return reorganized_data

def prepare_grpo_dataset(data_list):
    """å‡†å¤‡GRPOè®­ç»ƒæ•°æ®é›†"""
    print("ğŸ”„ å‡†å¤‡GRPOæ•°æ®é›†...")
    
    # ä¸ºGRPOæ·»åŠ promptå­—æ®µï¼ˆå…³é”®ä¿®å¤ï¼‰
    for item in data_list:
        # ä¼˜å…ˆä½¿ç”¨messageså­—æ®µï¼ˆå…¼å®¹åŸæœ‰é€»è¾‘ï¼‰
        if 'messages' in item and len(item['messages']) > 0:
            user_message = item['messages'][0]['content']
            item['prompt'] = user_message
            del item['messages']
        else:
            # æ ¸å¿ƒä¿®å¤ï¼šä»instructionå’Œinputç”Ÿæˆprompt
            instruction = item.get('instruction', '')
            input_text = item.get('input', '')
            # æ‹¼æ¥æˆå®Œæ•´promptï¼ˆä¸åŸload_and_process_dataé€»è¾‘ä¸€è‡´ï¼‰
            item['prompt'] = f"{instruction}\n\n{input_text}".strip()
    
    dataset = Dataset.from_list(data_list)
    print(f"âœ… GRPOæ•°æ®é›†å‡†å¤‡å®Œæˆï¼Œå…±{len(dataset)}ä¸ªæ ·æœ¬")
    
    # éªŒè¯promptæ˜¯å¦æˆåŠŸæ·»åŠ 
    if len(dataset) > 0 and 'prompt' in dataset[0]:
        print(f"   ç¤ºä¾‹prompt: {dataset[0]['prompt'][:50]}...")  # æ‰“å°å‰50å­—ç¬¦
    else:
        print("âš ï¸ è­¦å‘Šï¼šæ•°æ®é›†ä»æœªåŒ…å«'prompt'å­—æ®µï¼")
    
    return dataset


def validate_dataset_format(dataset):
    """éªŒè¯æ•°æ®é›†æ ¼å¼"""
    print("ğŸ” éªŒè¯æ•°æ®æ ¼å¼...")
    sample_item = dataset[0]
    print(f"   æ•°æ®å­—æ®µ: {list(sample_item.keys())}")
    if 'prompt' in sample_item:
        print(f"   ç¤ºä¾‹prompté•¿åº¦: {len(sample_item['prompt'])}")
    if 'label' in sample_item:
        print(f"   ç¤ºä¾‹MNLIæ ‡ç­¾: {sample_item['label']}")
    print("âœ… æ•°æ®æ ¼å¼éªŒè¯å®Œæˆ")
    
    return True

def create_optimized_dataset(file_path, max_samples=None, batch_size=4):
    """åˆ›å»ºä¼˜åŒ–çš„æ•°æ®é›†ï¼ˆå®Œæ•´æµç¨‹ï¼‰"""
    # åŠ è½½æ•°æ®
    data = load_synthesis_data(file_path, max_samples)
    print(f"ğŸ”„ åŸå§‹æ•°æ®åŠ è½½å®Œæˆï¼Œå…±{len(data)}ä¸ªæ ·æœ¬")
    
    # é¦–å…ˆå¤„ç†æ•°æ®ï¼Œæå–æ ‡ç­¾
    processed_data = []
    for item in data:
        input_text = item.get('input', '')
        output_text = item.get('output', '')
        target_label = 'neutral'  # é»˜è®¤æ ‡ç­¾
        
        # æ–¹æ³•1ï¼šä»outputå­—æ®µçš„JSONä¸­æå–æ ‡ç­¾ï¼ˆæœ€å‡†ç¡®ï¼‰
        try:
            import json
            # è§£æoutputä¸­çš„JSON
            output_json = json.loads(output_text)
            if 'output' in output_json:
                target_label = output_json['output']
        except (json.JSONDecodeError, KeyError, TypeError):
            # JSONè§£æå¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨å…¶ä»–æ–¹æ³•
            pass
        
        # æ–¹æ³•2ï¼šå¦‚æœæ–¹æ³•1å¤±è´¥ï¼Œä»inputå­—æ®µä¸­æå–
        if target_label == 'neutral':
            if 'Target label (must match exactly):' in input_text:
                # æå–Target labelåé¢çš„å†…å®¹
                label_line = input_text.split('Target label (must match exactly):')[1].split('\n')[0].strip()
                target_label = label_line
        
        # éªŒè¯æ ‡ç­¾æ˜¯å¦æœ‰æ•ˆ
        if target_label not in ['entailment', 'contradiction', 'neutral']:
            target_label = 'neutral'  # æ— æ•ˆæ ‡ç­¾é»˜è®¤ä¸ºneutral
        
        # æ·»åŠ æ ‡ç­¾åˆ°æ•°æ®é¡¹
        item['label'] = target_label
        processed_data.append(item)
    
    # åº”ç”¨æ ‡ç­¾åˆ†ç»„ä¼˜åŒ–
    print("ğŸ§  åº”ç”¨MNLIæ ‡ç­¾åˆ†ç»„ä¼˜åŒ–...")
    grouped_data = create_label_grouped_dataset(processed_data, batch_size)
    print(f"âœ… æ ‡ç­¾åˆ†ç»„å®Œæˆï¼Œä¼˜åŒ–åæ•°æ®é‡: {len(grouped_data)}ä¸ªæ ·æœ¬")
    
    # å‡†å¤‡GRPOæ•°æ®é›†
    dataset = prepare_grpo_dataset(grouped_data)
    
    # éªŒè¯æ ¼å¼
    validate_dataset_format(dataset)
    
    return dataset, grouped_data